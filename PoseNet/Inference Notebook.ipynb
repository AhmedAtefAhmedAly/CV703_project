{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e640015",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'sam6d' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n sam6d ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
    "import pyrender\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from bpc.inference.utils.camera_utils import load_camera_params\n",
    "from bpc.inference.process_pose import PoseEstimator, PoseEstimatorParams\n",
    "from bpc.utils.data_utils import Capture, render_mask\n",
    "import bpc.utils.data_utils as du\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a1973f-7beb-4758-837a-1fa5887ae9ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'sam6d' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n sam6d ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def render_mask_cv(obj, K, RT, imsize, mesh_poses):\n",
    "    h, w = imsize[1], imsize[0]\n",
    "    mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    # print(\"\\n \\n Bahey \\n \\n \", len(mesh_poses), mesh_poses[0].shape)\n",
    "    vertices = obj.vertices\n",
    "    faces = obj.faces\n",
    " \n",
    "    for pose in mesh_poses:\n",
    "        # Full transformation: Object -> world -> camera\n",
    "        verts_homo = np.hstack((vertices, np.ones((vertices.shape[0], 1))))  # Nx4\n",
    "        world_vertices = (pose @ verts_homo.T).T  # Object to world\n",
    "        camera_vertices = (RT @ np.hstack((world_vertices[:, :3], np.ones((world_vertices.shape[0], 1)))).T).T[:, :3]  # World to camera\n",
    " \n",
    "        # Now project camera space points\n",
    "        projected_pts, _ = cv2.projectPoints(\n",
    "            camera_vertices,\n",
    "            np.zeros(3),  # Already in camera space\n",
    "            np.zeros(3),\n",
    "            K, None\n",
    "        )\n",
    "        projected_pts = projected_pts.squeeze().astype(np.int32)\n",
    " \n",
    "        # Fill each triangle face\n",
    "        for face in faces:\n",
    "            pts = projected_pts[face]\n",
    "            cv2.fillConvexPoly(mask, pts, 255)\n",
    " \n",
    "    return mask, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57a8b1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'sam6d' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n sam6d ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# scene_dir = \"./datasets/ipd_bop_data_jan25_1/train_pbr/000000/\"\n",
    "# models_dir = './datasets/ipd_bop_data_jan25_1/models_eval/'\n",
    "scene_dir = \"./datasets/ipd_val/val/000001/\"\n",
    "models_dir = './datasets/ipd_models/models/'\n",
    "cam_ids = [\"cam1\", \"cam2\", \"cam3\"]\n",
    "image_id = 0\n",
    "obj_id = 14\n",
    "obj_id_path = str(1000000+obj_id)[1:]\n",
    "ply_file = os.path.join(models_dir, f\"obj_{obj_id_path}.ply\")\n",
    "obj = trimesh.load(ply_file)\n",
    "yolo_model_path = f'models/detection/obj_{obj_id}/yolo11-detection-obj_{obj_id}.pt'\n",
    "pose_model_path = f'models/rot_models/rot_{obj_id}.pth'\n",
    " \n",
    "pose_params = PoseEstimatorParams(yolo_model_path=yolo_model_path,\n",
    "                                  pose_model_path=pose_model_path,\n",
    "                                  yolo_conf_thresh=0.01)\n",
    "pose_estimator = PoseEstimator(pose_params)\n",
    "t = time.time()\n",
    "capture = Capture.from_dir(scene_dir, cam_ids, image_id, obj_id)\n",
    "detections = pose_estimator._detect(capture)\n",
    "pose_predictions = pose_estimator._match(capture, detections)\n",
    "pose_estimator._estimate_rotation(pose_predictions)\n",
    "print(time.time() - t)\n",
    "\n",
    "for idx in range(len(capture.Ks)):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(capture.images[idx])\n",
    "    mask, _ = render_mask_cv(\n",
    "        obj,\n",
    "        capture.Ks[idx],\n",
    "        capture.RTs[idx],\n",
    "        capture.images[0].shape[:2][::-1],\n",
    "        [x.pose for x in pose_predictions]\n",
    "    )\n",
    "    plt.imshow(mask, alpha=0.5, cmap='jet')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5dc72d-1efa-447d-806e-89d9bf353e14",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'sam6d' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n sam6d ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# from bpc.pose.models.metrics import compute_add, compute_mvd, compute_rotation_translation_error\n",
    " \n",
    "# all_add, all_mvd, tp, fp, fn = [], [], 0, 0, 0\n",
    "\n",
    "# for cam_idx in range(len(capture.Ks)):  # Per camera\n",
    "#     gt_R, gt_t = capture.RTs[cam_idx][:3, :3], capture.RTs[cam_idx][:3, 3:]\n",
    " \n",
    "#     try:\n",
    "#         pred = pose_predictions[cam_idx]\n",
    "#     except IndexError:\n",
    "#         fn += 1\n",
    "#         continue\n",
    " \n",
    "#     pred_R, pred_t = pred.pose[:3, :3], pred.pose[:3, 3:]\n",
    "#     # print(pred_R, pred_t) \n",
    "#     # Metrics\n",
    "#     add = compute_add(gt_R, gt_t, pred_R, pred_t, obj.vertices)\n",
    "#     mvd = compute_mvd(gt_R, gt_t, pred_R, pred_t, obj.vertices)\n",
    "#     rot_err, trans_err = compute_rotation_translation_error(gt_R, gt_t, pred_R, pred_t)\n",
    "#     print(\"\\n Rotation error\", rot_err, \"\\n Translation error\", trans_err)\n",
    "\n",
    " \n",
    "#     all_add.append(add)\n",
    "#     all_mvd.append(mvd)\n",
    " \n",
    "#     if trans_err < 10 and rot_err < 10:\n",
    "#         tp += 1\n",
    "#     else:\n",
    "#         fp += 1\n",
    " \n",
    " \n",
    "# # Final aggregate results\n",
    "# recall = tp / (tp + 1e-6)\n",
    "# precision = tp / (tp + fp + 1e-6)\n",
    " \n",
    "# print(f\"\\n[Scene {scene_dir}, Image {image_id}]\")\n",
    "# print(f\"Precision @ 10mm/10째: {precision:.4f}\")\n",
    "# print(f\"Recall @ 10mm/10째: {recall:.4f}\")\n",
    "# print(f\"Mean ADD: {np.mean(all_add):.4f} mm\")\n",
    "# print(f\"Mean MVD: {np.mean(all_mvd):.4f} mm\")\n",
    "\n",
    "def pairwise_rotation_errors(pred_poses, gt_poses):\n",
    "    N, M = pred_poses.shape[0], gt_poses.shape[0]\n",
    "    pred_R = pred_poses[:, :3, :3]  # (N, 3, 3)\n",
    "    gt_R   = gt_poses[:, :3, :3]    # (M, 3, 3)\n",
    "\n",
    "    rot_errors = np.zeros((N, M))\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            R_rel = pred_R[i].T @ gt_R[j]\n",
    "            trace = np.trace(R_rel)\n",
    "            trace = np.clip(trace, -1.0, 3.0)  # numerical stability\n",
    "            angle_rad = np.arccos((trace - 1) / 2.0)\n",
    "            rot_errors[i, j] = np.degrees(angle_rad)\n",
    "\n",
    "    return rot_errors  # shape: (N, M)\n",
    "\n",
    "def pairwise_translation_errors(pred_poses, gt_poses):\n",
    "    # Extract translation vectors\n",
    "    pred_t = pred_poses[:, :3, 3]  # (N, 3)\n",
    "    gt_t   = gt_poses[:, :3, 3]    # (M, 3)\n",
    "\n",
    "    # Compute all pairwise L2 distances\n",
    "    # Shape: (N, M)\n",
    "    dists = np.linalg.norm(pred_t[:, None, :] - gt_t[None, :, :], axis=-1)\n",
    "    \n",
    "    return dists\n",
    "    \n",
    "\n",
    "def compute_pose_errors(pred_poses, gt_poses):\n",
    "    assert pred_poses.shape[0] == gt_poses.shape[0], \"Mismatch in number of poses\"\n",
    "\n",
    "    rot_errors = []\n",
    "    trans_errors = []\n",
    "\n",
    "    for pred, gt in zip(pred_poses, gt_poses):\n",
    "        R_pred, t_pred = pred[:3, :3], pred[:3, 3]\n",
    "        R_gt,   t_gt   = gt[:3, :3],   gt[:3, 3]\n",
    "\n",
    "        # Translation error\n",
    "        t_error = np.linalg.norm(t_pred - t_gt)\n",
    "\n",
    "        # Rotation error (in degrees)\n",
    "        R_rel = R_pred.T @ R_gt\n",
    "        trace = np.trace(R_rel)\n",
    "        angle_rad = np.arccos(np.clip((trace - 1) / 2.0, -1.0, 1.0))\n",
    "        r_error = np.degrees(angle_rad)\n",
    "\n",
    "        trans_errors.append(t_error)\n",
    "        rot_errors.append(r_error)\n",
    "\n",
    "    return np.array(rot_errors), np.array(trans_errors)\n",
    "\n",
    "\n",
    "from bpc.pose.models.metrics import compute_add, compute_mvd, compute_rotation_translation_error\n",
    " \n",
    "all_add, all_mvd, tp, fp, fn = [], [], 0, 0, 0\n",
    "\n",
    "for cam_idx in range(len(capture.Ks)):  # Per camera\n",
    "    pose_matrix = capture.RTs[cam_idx]\n",
    "    gt_poses = capture.gt_poses\n",
    "\n",
    "    poses_world = []\n",
    "    for pose_pred in pose_predictions:\n",
    "        poses_world.append(pose_pred.pose)\n",
    "\n",
    "    poses_world = np.array(poses_world)\n",
    "        \n",
    "    poses_camera = pose_matrix @ poses_world\n",
    "\n",
    "    all_trans_errors = pairwise_translation_errors(poses_camera, gt_poses)\n",
    "    all_rots_errors = pairwise_rotation_errors(poses_camera, gt_poses)\n",
    "    best_pred_indices = np.argmin(all_trans_errors, axis=0)  # (M,)\n",
    "    matched_pred_poses = poses_camera[best_pred_indices]  # shape: (M, 4, 4)\n",
    "\n",
    "    rot_errors, trans_errors = compute_pose_errors(matched_pred_poses, gt_poses)\n",
    "    # print(best_pred_indices, matched_pred_poses.shape)\n",
    "    # print(all_trans_errors)\n",
    "    # print(\"\\n \\n\")\n",
    "    print(rot_errors, trans_errors)\n",
    "    # print(all_rots_errors)\n",
    "    break\n",
    "    # cam_R_w2c, cam_t_w2c, cam_K = capture.RTs[cam_idx][:3, :3], capture.RTs[cam_idx][:3, 3:], capture.Ks[0]\n",
    "    # print(\"\\n GT Poses \\n\", pose_matrix.shape, gt_pose.shape, poses_camera.shape)\n",
    "    # T_cam_w2c = np.eye(4)\n",
    "    # T_cam_w2c[:3, :3] = cam_R_w2c\n",
    "    # T_cam_w2c[:3, 3] = cam_t_w2c\n",
    "    # print(cam_R.shape,\"\\n\")\n",
    "    # print(cam_t.shape,\"\\n\")\n",
    "    # print(cam_K.shape,\"\\n\")\n",
    " \n",
    "#     pred_R, pred_t = pred.pose[:3, :3], pred.pose[:3, 3:]\n",
    "#     # print(pred_R, pred_t) \n",
    "#     # Metrics\n",
    "#     add = compute_add(gt_R, gt_t, pred_R, pred_t, obj.vertices)\n",
    "#     mvd = compute_mvd(gt_R, gt_t, pred_R, pred_t, obj.vertices)\n",
    "#     rot_err, trans_err = compute_rotation_translation_error(gt_R, gt_t, pred_R, pred_t)\n",
    "#     print(\"\\n Rotation error\", rot_err, \"\\n Translation error\", trans_err)\n",
    "\n",
    " \n",
    "#     all_add.append(add)\n",
    "#     all_mvd.append(mvd)\n",
    " \n",
    "#     if trans_err < 10 and rot_err < 10:\n",
    "#         tp += 1\n",
    "#     else:\n",
    "#         fp += 1\n",
    " \n",
    " \n",
    "# # Final aggregate results\n",
    "# recall = tp / (tp + 1e-6)\n",
    "# precision = tp / (tp + fp + 1e-6)\n",
    " \n",
    "# print(f\"\\n[Scene {scene_dir}, Image {image_id}]\")\n",
    "# print(f\"Precision @ 10mm/10째: {precision:.4f}\")\n",
    "# print(f\"Recall @ 10mm/10째: {recall:.4f}\")\n",
    "# print(f\"Mean ADD: {np.mean(all_add):.4f} mm\")\n",
    "# print(f\"Mean MVD: {np.mean(all_mvd):.4f} mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914a2951-34a6-4141-b257-49884a6a8b62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'sam6d' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n sam6d ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def orthogonalize_rotation(R):\n",
    "    U, _, Vt = np.linalg.svd(R)\n",
    "    R_ortho = U @ Vt\n",
    "    # Ensure proper rotation (det = +1)\n",
    "    if np.linalg.det(R_ortho) < 0:\n",
    "        R_ortho *= -1\n",
    "    return R_ortho\n",
    "\n",
    "scene_base_dir = \"/l/users/ahmed.aly/ipd/val/\"\n",
    "models_dir = \"/l/users/ahmed.aly/models/\"\n",
    "output_dir = \"./outputs_14_2/\"\n",
    "cam_ids = [\"cam1\", \"cam2\", \"cam3\"]\n",
    "obj_ids = [14]\n",
    "\n",
    "scenes_list = sorted(os.listdir(scene_base_dir))\n",
    "for scene_id, scene in enumerate(scenes_list):\n",
    "    os.makedirs(os.path.join(output_dir, scene), exist_ok=True)\n",
    "    scene_dir = os.path.join(scene_base_dir, scene)\n",
    "    cam_dir = os.path.join(scene_dir, \"rgb_cam1\")\n",
    "    images_list = sorted(os.listdir(cam_dir))\n",
    "    for image_id, image_name in enumerate(images_list):\n",
    "        for obj_id in obj_ids:    \n",
    "            obj_id_path = str(1000000+obj_id)[1:]\n",
    "            ply_file = os.path.join(models_dir, f\"obj_{obj_id_path}.ply\")\n",
    "            obj = trimesh.load(ply_file)\n",
    "            yolo_model_path = f'models/detection/obj_{obj_id}/yolo11-detection-obj_{obj_id}.pt'\n",
    "            pose_model_path = f'models/rot_models/rot_{obj_id}.pth'\n",
    "\n",
    "            pose_params = PoseEstimatorParams(yolo_model_path=yolo_model_path,\n",
    "                                              pose_model_path=pose_model_path,\n",
    "                                              yolo_conf_thresh=0.01)\n",
    "            pose_estimator = PoseEstimator(pose_params)\n",
    "            t = time.time()\n",
    "            capture = Capture.from_dir(scene_dir, cam_ids, image_id, obj_id)\n",
    "            detections = pose_estimator._detect(capture)\n",
    "            pose_predictions = pose_estimator._match(capture, detections)\n",
    "            pose_estimator._estimate_rotation(pose_predictions)\n",
    "            print(time.time() - t)\n",
    "\n",
    "            for cam_idx in range(len(capture.Ks)):  # Per camera\n",
    "                ## Create cam directory\n",
    "                os.makedirs(os.path.join(output_dir, scene, \"cam\"+str(cam_idx+1)), exist_ok=True)\n",
    "                ## Create image directory inside cam directory\n",
    "                os.makedirs(os.path.join(output_dir, scene, \"cam\"+str(cam_idx+1), image_name[:-4]), exist_ok=True)\n",
    "                os.makedirs(os.path.join(output_dir, scene, \"cam\"+str(cam_idx+1), image_name[:-4], \"sam6d_results\"), exist_ok=True)\n",
    "\n",
    "                \n",
    "                pose_matrix = capture.RTs[cam_idx]\n",
    "                print(\"\\n \\n\", cam_idx, \"\\n \\n\", pose_matrix)\n",
    "                poses_world = np.array([pose_pred.pose for pose_pred in pose_predictions])\n",
    "                if len(poses_world) > 0:\n",
    "                    poses_camera = pose_matrix @ poses_world\n",
    "                    pred_t = poses_camera[:, :3, 3]  # (N, 3)\n",
    "                    pred_R = poses_camera[:, :3, :3]  # (N, 3, 3)\n",
    "                    json_preds = []\n",
    "                    for pred_pose_id in range(len(poses_world)):  \n",
    "                        pred_R[pred_pose_id] = orthogonalize_rotation(pred_R[pred_pose_id])\n",
    "                        json_dict = {\"scene_id\": scene_id,\n",
    "                                     \"image_id\": image_id,\n",
    "                                     \"category_id\": obj_id,\n",
    "                                     \"R\": pred_R[pred_pose_id].tolist(),\n",
    "                                     \"t\": pred_t[pred_pose_id].tolist()\n",
    "                                    }\n",
    "                        json_preds.append(json_dict)\n",
    "\n",
    "                    with open(os.path.join(output_dir, scene, \"cam\"+str(cam_idx+1), image_name[:-4], \"sam6d_results/detection_pem.json\"), \"w\") as f:\n",
    "                        json.dump(json_preds, f, indent=4)\n",
    "\n",
    "\n",
    "# for cam in cam_ids:\n",
    "\n",
    "# for idx in range(len(capture.Ks)):\n",
    "#     plt.figure(figsize=(15, 15))\n",
    "#     plt.imshow(capture.images[idx])\n",
    "#     mask, _ = render_mask_cv(\n",
    "#         obj,\n",
    "#         capture.Ks[idx],\n",
    "#         capture.RTs[idx],\n",
    "#         capture.images[0].shape[:2][::-1],\n",
    "#         [x.pose for x in pose_predictions]\n",
    "#     )\n",
    "#     plt.imshow(mask, alpha=0.5, cmap='jet')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for cam_idx in range(len(capture.Ks)):  # Per camera\n",
    "#     pose_matrix = capture.RTs[cam_idx]\n",
    "#     gt_poses = capture.gt_poses\n",
    "\n",
    "#     poses_world = []\n",
    "#     for pose_pred in pose_predictions:\n",
    "#         poses_world.append(pose_pred.pose)\n",
    "\n",
    "#     poses_world = np.array(poses_world)\n",
    "        \n",
    "#     poses_camera = pose_matrix @ poses_world\n",
    "#     pred_t = poses_camera[:, :3, 3]  # (N, 3)\n",
    "#     pred_R = poses_camera[:, :3, :3]  # (N, 3, 3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
